{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010dfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_recognition as VTT\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef196875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42148",
   "metadata": {},
   "source": [
    "Voice To Emotion _ 곽민창"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d53988",
   "metadata": {},
   "outputs": [],
   "source": [
    "VTE_Array = []\n",
    "TTE_Array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28bc830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 207ms/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"WAV/\"):\n",
    "    filename = normalize('NFC', filename)\n",
    "    try:\n",
    "        if '.wav' not in filename in filename:\n",
    "            continue\n",
    "        wav, sr = librosa.load(\"WAV/\" + filename, sr=None)\n",
    "        print(filename)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=100, n_fft=400, hop_length=160)\n",
    "        mfcc = sklearn.preprocessing.scale(mfcc, axis=1)\n",
    "        padded_mfcc = pad2d(mfcc, 700)\n",
    "        padded_mfcc = np.expand_dims(padded_mfcc, 0)\n",
    "        \n",
    "        VTE_result = model.predict(padded_mfcc)\n",
    "        VTE_Array.append(VTE_result)\n",
    "        #result 값인 VTE_result 로 scoring 하여 배열에 추가하는 방향으로 다시 코드 작성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7100cdca",
   "metadata": {},
   "source": [
    "Voice To Text _ 이승렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57295d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = VTT.Recognizer()\n",
    "name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"WAV/\"):\n",
    "    filename = normalize('NFC', filename)\n",
    "    try:\n",
    "        if '.wav' not in filename in filename:\n",
    "            continue\n",
    "        \n",
    "        kr_audio = VTT.AudioFile(\"WAV/\" + filename)\n",
    "        with kr_audio as source:\n",
    "            VTT_audio = r.record(source)\n",
    "        temp = r.recognize_google(VTT_audio, language='ko-KR')\n",
    "        \n",
    "        sys.stdout = open(\"TXT/\" + str(name) + '.txt', 'w')\n",
    "        #sys.stdout.close()\n",
    "        name = name + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7858a2",
   "metadata": {},
   "source": [
    "Text To Emotion _ 김지호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "import json\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "830e2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, 'r', encoding = 'UTF8') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e908b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9049e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(\"2. kimjiho/문자열_train_data.txt\")\n",
    "test_data = read_data(\"2. kimjiho/문자열_test_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('2. kimjiho/train_docs.json'):\n",
    "    with open('2. kimjiho/train_docs.json',encoding=\"UTF-8\")as f:\n",
    "        train_docs = json.load(f)\n",
    "    with open('2. kimjiho/test_docs.json',encoding=\"UTF-8\")as f:\n",
    "        test_docs = json.load(f)\n",
    "else:\n",
    "    train_docs = [(tokenize(row[0]),row[1]) for row in train_data]\n",
    "    test_docs = [(tokenize(row[0]),row[1]) for row in test_data]\n",
    "    with open('2. kimjiho/train_docs.json','w',encoding=\"UTF-8\")as make_file:\n",
    "        json.dump(train_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
    "    with open('2. kimjiho/test_docs.json','w',encoding=\"UTF-8\")as make_file:\n",
    "        json.dump(test_docs, make_file, ensure_ascii=False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "text = nltk.Text(tokens, name='NMSC')\n",
    "selected_words = [f[0] for f in text.vocab().most_common(20000)]\n",
    "def term_frequency(doc):\n",
    "    return [doc.count(word) for word in selected_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33696f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#감정 추출해주는 Result 함수\n",
    "def predict_pos_neg(review):\n",
    "    token = tokenize(review)\n",
    "    tf = term_frequency(token)\n",
    "    data = np.expand_dims(np.array(tf).astype('float32'),axis=0)\n",
    "    score = float(model.predict(data))\n",
    "    if(score>0.5):\n",
    "        print(\"오늘의 긍정지수는 {:2f}%입니다.\\n\".format(score*100))\n",
    "        return score*100\n",
    "    else:\n",
    "        print(\"오늘의 부정지수는 {:2f}%입니다.\\n\".format((1-score)*100))\n",
    "        return score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"TXT/\"):\n",
    "    filename = normalize('NFC', filename)\n",
    "    try:\n",
    "        if '.txt' not in filename in filename:\n",
    "            continue\n",
    "        TTE_Result = predict_pos_neg(\"input 입력할것\")\n",
    "        TTE_Array.append(TTE_Result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
