{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010dfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_recognition as VTT\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135857b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '1. VoiceToEmotion/Data/Sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef196875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e45110",
   "metadata": {},
   "source": [
    "Voice To Emotion _ 곽민창"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e81b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sr :  48000\n",
      "wav shape :  (252720,)\n",
      "length :  5.265 secs\n"
     ]
    }
   ],
   "source": [
    "#Audio = 원본 통화녹음 파일 Data/Sample/Sample1.wav\n",
    "\n",
    "audio, sr = librosa.load(DATA_DIR + '/Sample1.wav', sr=None)\n",
    "print('sr : ', sr)\n",
    "print('wav shape : ', audio.shape)\n",
    "print('length : ', audio.shape[0]/float(sr), 'secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d59fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwarkmc\\.conda\\envs\\capstone\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\kwarkmc\\.conda\\envs\\capstone\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:239: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kwarkmc\\.conda\\envs\\capstone\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:258: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=100, n_fft=400, hop_length=160)\n",
    "mfcc = sklearn.preprocessing.scale(mfcc, axis=1)\n",
    "padded_mfcc = pad2d(mfcc, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0aa0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_mfcc = np.expand_dims(padded_mfcc, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28bc830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 207ms/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('weight.h5')\n",
    "VTE_result = model.predict(padded_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b8fc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9997571, 0.9709723]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VTE_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4740ad4a",
   "metadata": {},
   "source": [
    "Voice To Text _ 이승렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c6884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = VTT.Recognizer()\n",
    "kr_audio = VTT.AudioFile(DATA_DIR + '/Sample1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba8f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097fa91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with kr_audio as source:\n",
    "    VTT_audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2111aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.82105619,\n",
      "                           'transcript': '얼굴은 화끈 화끈 하고 가슴이 무서워 하는 사람처럼 뛰어 '\n",
      "                                         '놀았습니다'},\n",
      "                       {'transcript': '얼굴은 화끈 화끈 하고 가슴이 무서워하는 사람처럼 뛰어 놀았습니다'},\n",
      "                       {'transcript': '얼굴은 화끈화끈 하고 가슴이 무서워 하는 사람처럼 뛰어 놀았습니다'},\n",
      "                       {'transcript': '얼굴은 화끈화끈 하고 가슴이 무서워하는 사람처럼 뛰어 놀았습니다'},\n",
      "                       {'transcript': '얼굴은 화끈 화끈 하고 가슴이 무서워 하는 사람처럼 띠 놀았습니다'}],\n",
      "    'final': True}\n"
     ]
    }
   ],
   "source": [
    "temp = r.recognize_google(VTT_audio, language='ko-KR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be2bae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(str(name) + '.txt', 'w')\n",
    "print(temp)\n",
    "#sys.stdout.close()\n",
    "name = name + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86514d",
   "metadata": {},
   "source": [
    "Text To Emotion _ 김지호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "import json\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "830e2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, 'r', encoding = 'UTF8') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e3d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "993fbbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(\"2. kimjiho/문자열_train_data.txt\")\n",
    "test_data = read_data(\"2. kimjiho/문자열_test_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e80e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('train_docs.json'):\n",
    "    with open('train_docs.json',encoding=\"UTF-8\")as f:\n",
    "        train_docs = json.load(f)\n",
    "    with open('test_docs.json',encoding=\"UTF-8\")as f:\n",
    "        test_docs = json.load(f)\n",
    "else:\n",
    "    train_docs = [(tokenize(row[0]),row[1]) for row in train_data]\n",
    "    test_docs = [(tokenize(row[0]),row[1]) for row in test_data]\n",
    "    with open('train_docs.json','w',encoding=\"UTF-8\")as make_file:\n",
    "        json.dump(train_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
    "    with open('test_docs.json','w',encoding=\"UTF-8\")as make_file:\n",
    "        json.dump(test_docs, make_file, ensure_ascii=False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "text = nltk.Text(tokens, name='NMSC')\n",
    "selected_words = [f[0] for f in text.vocab().most_common(20000)]\n",
    "def term_frequency(doc):\n",
    "    return [doc.count(word) for word in selected_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f253b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos_neg(review):\n",
    "    token = tokenize(review)\n",
    "    tf = term_frequency(token)\n",
    "    data = np.expand_dims(np.array(tf).astype('float32'),axis=0)\n",
    "    score = float(model.predict(data))\n",
    "    if(score>0.5):\n",
    "        print(\"오늘의 긍정지수는 {:2f}%입니다.\\n\".format(score*100))\n",
    "        TTE_Result = score*100\n",
    "    else:\n",
    "        print(\"오늘의 부정지수는 {:2f}%입니다.\\n\".format((1-score)*100))\n",
    "        TTE_Result = score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb816db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pos_neg(\"input 입력할것\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
